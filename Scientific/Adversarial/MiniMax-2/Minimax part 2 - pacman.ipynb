{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font face=\"XB Niloofar\" size=30>\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t\t<p></p>\n",
    "به نام خدا\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t\t<font color=#FF7500>\n",
    "دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "            </font>\n",
    "\t\t\t<p></p>\n",
    "\t\t\t<br />\n",
    "\t\t\t<br />\n",
    "زمستان ۱۳۹۷\n",
    "\t\t</div>\n",
    "\t\t<hr/>\n",
    "\t\t<font color=red size=6>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\n",
    "                هوش مصنوعی\n",
    "                <br>\n",
    "                Minimax\n",
    "            </div>\n",
    "\t\t</font>\n",
    "        <font color=red size=4>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\n",
    "                بخش دوم\n",
    "            </div>\n",
    "\t\t</font>\n",
    "        <br />\n",
    "\t\t<div align=center>\n",
    "عرفان فرهادی و محمد شریفی کیاسری\n",
    "        </div>\n",
    "\t\t<hr />\n",
    "\t\t<style type=\"text/css\" scoped>\n",
    "        p{\n",
    "        border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "        };\n",
    "        </style>\n",
    "\t\t<div>\n",
    "\t\t\t<h3>فهرست مطالب</h3>\n",
    "\t\t\t<ul style=\"margin-right: 0;\">\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#intro\">\n",
    "                        مقدمه و مرور مفاهیم\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#reflex\">\n",
    "                       عامل بازتابی و تابع ارزیابی\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#Minimax\">\n",
    "                       Minimax و هرس $\\alpha - \\beta$\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#manba\">\n",
    "                       منابع\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "مقدمه و مرور مفاهیم\n",
    "        </font>\n",
    "        <br>\n",
    "        در بخش قبلی با مسئلهٔ بازی‌های رقابتیِ دونفره آشنا شدیم و در مورد الگوریتم minimax برای حل این‌گونه مسائل صحبت کردیم. ایده‌ی محوری در این الگوریتم آن بود که با پیش‌بینی حرکت نفر بعدی و فرض بهینه بودن رفتار رقیب بهترین گزینهٔ ممکن را انتخاب می‌کنیم. با درپیش‌گیری همین رویکرد درخت حالات بازی را به دست می‌آوردیم و انتخاب مطلوب را انجام می‌دادیم. از سوی دیگر دیدیم که به دست آوردن درخت حالات و انجام دادن الگوریتم minimax برای اغلب بازی‌ها بسیار زمان‌بر است پس برای کاهش پیچیدگی و هزینه‌های آن با روش هرس آلفا-بتا آشنا شدیم که در آن با حذف برخی از شاخه‌ها حجم محاسبات را از نظر پیچیدگی زمانی و حافظه کاهش می‌دهد. از سوی دیگر با محدود کردن عمق و حدس زدن ارزش وضعیت‌های مختلف همین کاهش هزینه‌ها را از منظر دیگری امتحان کردیم. در کنار آشنایی با مفاهیم اصلی با بررسی دو بازی دوز و connect4 این الگوریتم‌ها را پیاده‌سازی کردیم. در ادامه قرار است دست‌هایمان را به کد آلوده کنیم و با بررسی یک مسئلهٔ پیچیده‌تر هم با مفهوم تابع ارزیابی (evaluation function) بیش‌تر آشنا می‌شویم و هم کاربردهای minimax را در بازی Pacman مرور می‌کنیم.\n",
    "        <br>\n",
    "        <img src=\"image/start.gif\" align=\"middle\" height=\"500\" width=\"500\"/>\n",
    "        <br>\n",
    "        بیایید یک بار pacman را بازی کنیم. در ژوپیتر نوت‌بوک با استفاده از دستور <code>run%</code> می‌توانیم دستورات معادل با <code>python</code> در ترمینال را اجرا کنیم. همچنین اگر به پوشهٔ layouts بروید تعدادی نقشهٔ بازی می‌بینید که با استفاده از دستور <code>run pacman.py -l layoutName%</code> آن‌ها را امتحان کنید \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Pacman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reflex\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "        <font color=#FF7500 size=6>\n",
    "عامل بازتابی و تابع ارزیابی\n",
    "        </font>\n",
    "        <br>\n",
    "       حال می‌خواهیم برنامه‌ای بنویسیم که به پک‌من بخت‌برگشته کمک کند تا روی پای خودش بایستد و در بازی برنده شود. فعلا برای شروع کار می‌خواهیم یک عامل بازتابی (Reflex Agent) بنویسم. به طور خلاصه یک عامل بازتابی ساده در هر لحظه تمام محیط را مشاهده می‌کند و بر اساس تعدادی شرط از پیش تعیین شده رفتار می‌کند. (در پیوست این دفترچه منابعی برای آشنایی بیش‌تر با Agentها معرفی شده است.) پس قصد داریم که یک عامل بازتابی بنویسیم. برای تست کردن این عامل از دستور زیر استفاده می‌کنیم. این دستور را اجرا کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -p ReflexAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/game_over.gif\" align=\"middle\" height=\"500\" width=\"500\"/><br>\n",
    "<div id=\"eval\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "        همان‌طور که مشاهده کردید پک‌من حرکت می‌کرد اما همیشه می‌باخت. دلیل این امر آن بود که در هر بازهٔ زمانی پک‌من از میان حرکت‌های ممکن یکی را به صورت تصادفی انتخاب می‌کند. می‌خواهیم این مشکل را به مرور رفع کنیم. پیشنهاد شما برای رفع این مشکل چیست؟ واضح است که باید سعی کنیم از میان حرکت‌های ممکن حرکتی را انجام  دهیم که بهترین باشد. اما معیار ما برای بهترین چیست؟ چه سازوکاری برای ارزیابی یک وضعیت از بازی ارائه می‌کنید؟ \n",
    "        <br>\n",
    "        بیایید فرض کنیم چنین تابعی برای ارزیابی هر حرکت و وضعیت بازی داریم. حال باید برای هر بازهٔ زمانی از بین حرکت‌های مجاز یک حرکت را انتخاب کنیم که طبعا می‌خواهیم مقدار تابع ارزیابی در این وضعیت بیشینه باشد. قطعه کد زیر این کار را انجام می‌دهد. به آن دقت کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ReflexAgentActionUtil.py\n",
    "import random\n",
    "def reflexAgentAction(reflexAgent, gameState):\n",
    "    legalMoves = gameState.getLegalActions()\n",
    "    # Choose one of the best actions\n",
    "    scores = [reflexAgent.evaluationFunction(gameState, action) for action in legalMoves]\n",
    "    bestScore = max(scores)\n",
    "    bestIndices = [index for index in range(len(scores)) if scores[index] == bestScore]\n",
    "    chosenIndex = random.choice(bestIndices) # Pick randomly among the best\n",
    "    return legalMoves[chosenIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        حال هنگام آن است که تابع ارزیابی را کامل کنیم. یک بار دیگر به ابتدای دفترچه رفته و خودتان بازی را انجام دهید و در حین بازی به این فکر کنید که برای بردن بازی هر حرکت را بر اساس چه معیارهایی انجام می‌دهید. نکته‌ی اساسی در مورد تابع ارزیابی آن است که مفهوم پیچیده‌ای در آن نهفته نیست که ما قصد داشته باشیم در این فترچه آن را به شما آموزش دهیم بلکه بیش‌تر از هر چیز به میزان دانش شما و نحوهٔ پیاده‌سازی تابع ارزیابی برمی‌گردد.\n",
    "        <br>\n",
    "        سعی کنید تابع ارزیابی زیر را تکمیل کنید. این تابع موقعیت فعلی، یک حرکت قانونی و خود عامل را به عنوان ورودی می‌گیرد و یک عدد به عنوان میزان خوب بودن وضعیت حاصل بعد از انجام حرکت خروجی می‌دهد. چند دادهٔ مناسب که با توجه به وضعیت بازی می‌تواند مورد استفاده قرار بگیرد نیز در ابتدای این تابع ضمیمه شده است.\n",
    "        <br>\n",
    "<b>        توجه</b>: با استفاده از دستور    <code>writefile folan.py%%</code> در واقع یک فایل را کاملا پاک می‌کنیم و از نو می‌نویسیم و لازم است برای لود شدن مجدد کرنل پایتون مورد استفاده در دفترچهٔ ژوپیتر را ری‌استارت کنیم که این کار از طریق <code>(os._exit(0</code> انجام‌پذیر است با این‌حال لازم است که عملیات تغییر پوشهٔ فعلی و لود کردن کتاب‌خانه‌ها را از طریق دستورهای <code>import os</code> یا <code>cd Pacman</code> انجام دهیم. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ReflexAgentEvalUtil.py\n",
    "import util\n",
    "def reflexAgentEval(reflexAgent, currentGameState, action):\n",
    "    # Useful information you can extract from a GameState (pacman.py)\n",
    "    successorGameState = currentGameState.generatePacmanSuccessor(action)\n",
    "    newPos = successorGameState.getPacmanPosition()\n",
    "    newFood = successorGameState.getFood()\n",
    "    newGhostStates = successorGameState.getGhostStates()\n",
    "    newScaredTimes = [ghostState.scaredTimer for ghostState in newGhostStates]\n",
    "    # your code here!\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Pacman\n",
    "%run pacman.py -p ReflexAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "     خب نتیجه چه بود؟ آیا در بردن بازی موفق شد؟ اگر نه باز هم تلاش کنید تا منطق بازی را به خوبی به یک تابع ارزیابی ترجمه کنید. این عامل مهمی در یک تابع ارزیابی است. مثلا به عمل‌کرد قطعه کد طولانی زیر در همین بازی دقت کنید. از آن‌جایی که به منطق بازی توجه درستی نشده عامل به جای حرکت متوالی روی نقطه‌ها بین چند وضعیت مردد می‌ماند و اگر روحی در زمین نباشد یا روح‌ها به سمت او نیایند هیچ‌گاه موفق به اتمام بازی نشود. این کد را مطالعه کنید و سعی کنید دلیل مشکلات آن را مشخص کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ReflexAgentEvalUtil.py\n",
    "import util\n",
    "def reflexAgentEval(reflexAgent, currentGameState, action):\n",
    "    # Useful information you can extract from a GameState (pacman.py)\n",
    "    successorGameState = currentGameState.generatePacmanSuccessor(action)\n",
    "    newPos = successorGameState.getPacmanPosition()\n",
    "    newFood = successorGameState.getFood()\n",
    "    newGhostStates = successorGameState.getGhostStates()\n",
    "    newScaredTimes = [ghostState.scaredTimer for ghostState in newGhostStates]\n",
    "\n",
    "    def sum_food_proximity(cur_pos, food_positions, norm=False):\n",
    "        food_distances = []\n",
    "        for food in food_positions:\n",
    "            food_distances.append(util.manhattanDistance(food, cur_pos))\n",
    "        if norm:\n",
    "            return normalize(sum(food_distances) if sum(food_distances) > 0 else 1)\n",
    "        else:\n",
    "            return sum(food_distances) if sum(food_distances) > 0 else 1\n",
    "\n",
    "    score = successorGameState.getScore()\n",
    "    def ghost_stuff(cur_pos, ghost_states, radius, scores):\n",
    "        num_ghosts = 0\n",
    "        for ghost in ghost_states:\n",
    "            if util.manhattanDistance(ghost.getPosition(), cur_pos) <= radius:\n",
    "                scores -= 30\n",
    "                num_ghosts += 1\n",
    "        return scores\n",
    "\n",
    "    def food_stuff(cur_pos, food_pos, cur_score):\n",
    "        new_food = sum_food_proximity(cur_pos, food_pos)\n",
    "        cur_food = sum_food_proximity(currentGameState.getPacmanPosition(), currentGameState.getFood().asList())\n",
    "        new_food = 1/new_food\n",
    "        cur_food = 1/cur_food\n",
    "        if new_food > cur_food:\n",
    "            cur_score += (new_food - cur_food) * 3\n",
    "        else:\n",
    "            cur_score -= 20\n",
    "\n",
    "        next_food_dist = closest_dot(cur_pos, food_pos)\n",
    "        cur_food_dist = closest_dot(currentGameState.getPacmanPosition(), currentGameState.getFood().asList())\n",
    "        if next_food_dist < cur_food_dist:\n",
    "            cur_score += (next_food_dist - cur_food_dist) * 3\n",
    "        else:\n",
    "            cur_score -= 20\n",
    "        return cur_score\n",
    "\n",
    "    def closest_dot(cur_pos, food_pos):\n",
    "        food_distances = []\n",
    "        for food in food_pos:\n",
    "            food_distances.append(util.manhattanDistance(food, cur_pos))\n",
    "        return min(food_distances) if len(food_distances) > 0 else 1\n",
    "\n",
    "\n",
    "    def normalize(distance, layout):\n",
    "        return distance\n",
    "\n",
    "    return food_stuff(newPos, newFood.asList(), ghost_stuff(newPos, newGhostStates, 2, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Pacman\n",
    "%run pacman.py -p ReflexAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        حالا که با یکی دو نمونه از توابع ارزیابی دست‌وپنجه نرم کردید، به قطعه کد پایین و عملکرد آن هم نگاه کنید. می‌بینید که هنوز هم جای کار دارد و گاهی گیر می‌کند اما اغلب مواقع بازی را با پیروزی به اتمام می‌رساند. سعی کنید که عمل‌کرد این کد را با توجه به این‌که برخورد با روح‌های سفید امتیاز دارد بهبود بخشید. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ReflexAgentEvalUtil.py\n",
    "import util\n",
    "def reflexAgentEval(reflexAgent, currentGameState, action):\n",
    "    # Useful information you can extract from a GameState (pacman.py)\n",
    "    successorGameState = currentGameState.generatePacmanSuccessor(action)\n",
    "    newPos = successorGameState.getPacmanPosition()\n",
    "    newFood = successorGameState.getFood()\n",
    "    newGhostStates = successorGameState.getGhostStates()\n",
    "    newScaredTimes = [ghostState.scaredTimer for ghostState in newGhostStates]\n",
    "\n",
    "    if successorGameState.isWin():\n",
    "        return float(\"inf\")\n",
    "\n",
    "    for ghostState in newGhostStates:\n",
    "        if util.manhattanDistance(ghostState.getPosition(), newPos) < 2 and ghostState.scaredTimer < 3:\n",
    "            return float(\"-inf\")\n",
    "\n",
    "    foodDist = []\n",
    "    for food in list(newFood.asList()):\n",
    "        foodDist.append(util.manhattanDistance(food, newPos))\n",
    "\n",
    "    foodSuccessor = 0\n",
    "    if (currentGameState.getNumFood() > successorGameState.getNumFood()):\n",
    "        foodSuccessor = 300\n",
    "\n",
    "    return successorGameState.getScore() - 5 * min(foodDist) + foodSuccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd Pacman\n",
    "%run pacman.py -p ReflexAgent\n",
    "%run pacman.py -p ReflexAgent -l trickyClassic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Minimax\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "        <font color=#FF7500 size=6>\n",
    "عامل Minimax و $\\alpha-\\beta$\n",
    "        </font>\n",
    "        <br>\n",
    "         در بخش قبلی یک Reflex Agent برای بازی پک‌من نوشتیم. اما توجه کنید در آن حالت تمامی اطلاعات بازی را داشتیم و می‌دانستیم که هر روح چه انتخابی انجام می‌دهد و کجا می‌رود و این را در تصمیم‌گیری‌مان اثر می‌دادیم با این حال می‌دانیم که بسیاری از بازی‌ها تماماً مشاهده‌پذیر نیستند. به همین جهت لازم است تا از الگوریتم‌های دیگری استفاده کنیم. در بخش قبلی با الگوریتم Minimax ، هرس کردن آن و قطع کردن آن به کمک تابع ارزیابی آشنا شدید؛ در این بخش می‌خواهیم یک عامل Minimax را ابتدائا پیاده‌سازی کنیم و سپس آن را هرس کنیم. لازم است توجه داشته باشیم که به دلیل زیاد بودن حجم ما حتما درخت را از جایی قطع می‌کنیم و مثلا در عمق دو از تابع ارزیابی استفاده می‌کنیم. از سوی دیگر به جهت وجود چند روح درخت ما کمی متفاوت از آن چیزی‌ست که در بخش قبلی دیدیم و به ازای هر روی یک لایهٔ Min وجود دارد. برای انجام این بخش لازم است که تابع ارزیابی شما باید وضعیت‌ها را ارزیابی کند نه actionها را.\n",
    "        <br>\n",
    "        <br>\n",
    "        با این توضیحات بیایید تا فرآیند پیاده‌سازی این عامل را بررسی کنیم. برای این‌که فعلا درگیر تابع ارزیابی نشویم تصور کنید در هر لحظه از زمان این مقدار برابر مقدار امتیاز پک‌من است. خب حالا یک بار فرآیند درخت minimax را در ذهن خود بیاورید. ما در هر طبقه رئوسی داشتیم. با توجه به نوع طبقه که max هست یا min، رئوس مقادیر بیشینه یا کمینه فرزندان‌شان را در درخت می‌پذیرفتند و اگر در درخت به قدر کافی پایین رفته بودیم مقدار رأس مورد نظر برابر مقدار تابع ارزیابی در آن رأس (وضعیت) بود. در نهایت مقدار  رأس ریشه به عنوان ماکسیمم انتخاب می‌شود. با توجه به این توضیحات سعی کنید که این عامل را پیاده‌سازی کنید. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile MinimaxAgentUtil.py\n",
    "from util import manhattanDistance\n",
    "from game import Directions\n",
    "def minimaxAgentAction(agent, gameState):\n",
    "    \"\"\"\n",
    "      Returns the minimax action from the current gameState using self.depth\n",
    "      and self.evaluationFunction.\n",
    "\n",
    "      Here are some method calls that might be useful when implementing minimax.\n",
    "\n",
    "      gameState.getLegalActions(agentIndex):\n",
    "        Returns a list of legal actions for an agent\n",
    "        agentIndex=0 means Pacman, ghosts are >= 1\n",
    "\n",
    "      gameState.generateSuccessor(agentIndex, action):\n",
    "        Returns the successor game state after an agent takes an action\n",
    "\n",
    "      gameState.getNumAgents():\n",
    "        Returns the total number of agents in the game\n",
    "    \"\"\"\n",
    "    #your code here\n",
    "return Directions.STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Pacman\n",
    "%run pacman.py -p MinimaxAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        پیشنهاد می‌کنیم بعد از پیاده‌سازی کد خودتان به کد پایین هم به عنوان یک نمونه نگاهی بیندازید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile MinimaxAgentUtil.py\n",
    "from util import manhattanDistance\n",
    "from game import Directions\n",
    "def minimaxAgentAction(agent, gameState):\n",
    "    maxValue = float(\"-inf\")\n",
    "    maxAction = Directions.STOP\n",
    "    for action in gameState.getLegalActions(0):\n",
    "        nextState = gameState.generateSuccessor(0, action)\n",
    "        nextValue = getValue(agent, nextState, 0, 1)\n",
    "        if nextValue > maxValue:\n",
    "            maxValue = nextValue\n",
    "            maxAction = action\n",
    "    return maxAction\n",
    "\n",
    "def getValue(agent, gameState, currentDepth, agentIndex):\n",
    "    if currentDepth == agent.depth or gameState.isWin() or gameState.isLose():\n",
    "        return agent.evaluationFunction(gameState)\n",
    "    elif agentIndex == 0:\n",
    "        return maxValue(agent, gameState,currentDepth)\n",
    "    else:\n",
    "        return minValue(agent, gameState,currentDepth,agentIndex)\n",
    "\n",
    "def maxValue(agent, gameState, currentDepth):\n",
    "    maxValue = float(\"-inf\")\n",
    "    for action in gameState.getLegalActions(0):\n",
    "        maxValue = max(maxValue, getValue(agent, gameState.generateSuccessor(0, action), currentDepth, 1))\n",
    "    return maxValue\n",
    "\n",
    "def minValue(agent, gameState, currentDepth, agentIndex):\n",
    "    minValue = float(\"inf\")\n",
    "    for action in gameState.getLegalActions(agentIndex):\n",
    "        if agentIndex == gameState.getNumAgents()-1:\n",
    "            minValue = min(minValue, getValue(agent, gameState.generateSuccessor(agentIndex, action), currentDepth+1, 0))\n",
    "        else:\n",
    "            minValue = min(minValue, getValue(agent, gameState.generateSuccessor(agentIndex, action), currentDepth, agentIndex+1))\n",
    "    return minValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Pacman\n",
    "%run pacman.py -p MinimaxAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "    بعد از پیاده‌سازی عامل Minimax به سراغ حرص آن می‌رویم. در این لحظه پیشنهاد می‌کنم از خواندن ادامهٔ این متن دست بکشید و سعی کنید اندکی به هدف و ایدهٔ این الگوریتم فکر کنید و برای خود آن را توضیح دهید سپس به خواندن ادامه دهید. <br><br>در این الگوریتم فرض بر آن است که اگر در حال محاسبهٔ مثلا یک رأس کمینه هستیم و یک عدد کوچک مثل بتا داریم دیگر لازم نیست شاخه‌هایی که مقدار تابع ارزیابی‌شان بیش از بتا است را بررسی کنیم زیرا می‌دانیم پاسخ این رأس کمینه نخواهند بود و همین قاعده به طور برعکس برای رئوس بیشینه و آلفا نیز برقرار است. همچنین اگر به عددی کوچک‌تر (بزرگ‌تر) از بتا (آلفا) برخوردیم مقدار بتا (آلفا) را آپدیت می‌کنیم. به شکل زیر توجه کنید \n",
    "    <img src=\"image/alpha-beta.png\" align=\"middle\" height=\"500\" width=\"500\"/>\n",
    "        حال به سراغ پیاده‌سازی همین ایدهٔ ساده با تغییر دادن عاملی که برای الگوریتم minimax نوشته بودیم می‌رویم. به پیاده‌سازی ساده زیر دقت کنید و آن را امتحان کنید. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile AlphaBetaAgentUtil.py\n",
    "from util import manhattanDistance\n",
    "from game import Directions\n",
    "\n",
    "def alphaBetaAgentAction(agent, gameState):\n",
    "\n",
    "    maxValue = float(\"-inf\")\n",
    "    alpha = float(\"-inf\")\n",
    "    beta = float(\"inf\")\n",
    "    maxAction = Directions.STOP\n",
    "    for action in gameState.getLegalActions(0):\n",
    "        nextState = gameState.generateSuccessor(0, action)\n",
    "        nextValue = getValue(agent, nextState, 0, 1, alpha, beta)\n",
    "        if nextValue > maxValue:\n",
    "            maxValue = nextValue\n",
    "            maxAction = action\n",
    "        alpha = max(alpha, maxValue)\n",
    "    return maxAction\n",
    "\n",
    "def getValue(agent, gameState, currentDepth, agentIndex, alpha, beta):\n",
    "    if currentDepth == agent.depth or gameState.isWin() or gameState.isLose():\n",
    "        return agent.evaluationFunction(gameState)\n",
    "    elif agentIndex == 0:\n",
    "        return maxValue(agent, gameState,currentDepth,alpha,beta)\n",
    "    else:\n",
    "        return minValue(agent, gameState,currentDepth,agentIndex,alpha,beta)\n",
    "\n",
    "def maxValue(agent, gameState, currentDepth, alpha, beta):\n",
    "    maxValue = float(\"-inf\")\n",
    "    for action in gameState.getLegalActions(0):\n",
    "        maxValue = max(maxValue, getValue(agent, gameState.generateSuccessor(0, action), currentDepth, 1, alpha, beta))\n",
    "        if maxValue > beta:\n",
    "            return maxValue\n",
    "        alpha = max(alpha, maxValue)\n",
    "    return maxValue\n",
    "\n",
    "def minValue(agent, gameState, currentDepth, agentIndex, alpha, beta):\n",
    "    minValue = float(\"inf\")\n",
    "    for action in gameState.getLegalActions(agentIndex):\n",
    "        if agentIndex == gameState.getNumAgents()-1:\n",
    "            minValue = min(minValue, getValue(agent, gameState.generateSuccessor(agentIndex, action), currentDepth+1, 0, alpha, beta))\n",
    "        else:\n",
    "            minValue = min(minValue, getValue(agent, gameState.generateSuccessor(agentIndex, action), currentDepth, agentIndex+1, alpha, beta))\n",
    "        if minValue < alpha:\n",
    "            return minValue\n",
    "        beta = min(beta, minValue)\n",
    "    return minValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Pacman\n",
    "%run pacman.py -p AlphaBetaAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "       عملکرد دو عامل minimax و alpha beta را چگونه می‌بینید؟ آیا دچار حلقه‌های بی‌پایان در تصمیم‌گیری پک‌من می‌شوند؟ به نظر شما مشکل از پیاده‌سازی الگوریتم‌هاست یا جای دیگری؟ و اگر جای دیگری کجا؟\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"reflex\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "        <font color=#FF7500 size=6>\n",
    "منابع\n",
    "        </font>\n",
    "        <br>\n",
    "        <a href=\"https://en.wikipedia.org/wiki/Intelligent_agent\"> معرفی اجمالی عامل‌های هوشمند </a>\n",
    "        <br>\n",
    "        <a href=\"http://ai.berkeley.edu/multiagent.html\">محتوای آموزشی پک‌من برای درس هوش مصنوعی دانشگاه برکلی</a>\n",
    "    </font>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
